<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="YAKUPOVA_Vera_Interdisziplin_re_transkulturelle_Analyse_von_">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="full">
                    <title type="main">Interdisziplinäre transkulturelle Analyse von Mensch-KI Interaktionen in Science-Fiction Literatur und im politischen Diskurs</title>
                    <title type="sub">Kulturelle Wahrnehmungen von Privatsphäre und KI-Überwachungstechnologien</title>
                </title>
                <author>
                    <persName>
                        <surname>Yakupova</surname>
                        <forename>Vera</forename>
                    </persName>
                    <affiliation>Trinity College Dublin, Republik Irland</affiliation>
                    <email>yakupovv@tcd.ie</email>
                    <idno type="ORCID">0009-0002-2752-4966</idno>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2024-12-02T21:44:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Bielefeld Computational Literary Studies Group</publisher>
                <address>
                    <addrLine>Universität Bielefeld</addrLine>
                    <addrLine>Universitätsstraße 25</addrLine>
                    <addrLine>33615 Bielefeld</addrLine>
                    <addrLine>Deutschland</addrLine>
                </address>
                <publisher>Digital History</publisher>
                <address>
                    <addrLine>Universität Bielefeld</addrLine>
                    <addrLine>Universitätsstraße 25</addrLine>
                    <addrLine>33615 Bielefeld</addrLine>
                    <addrLine>Deutschland</addrLine>
                </address>
                <publisher>Digital Linguistics Lab</publisher>
                <address>
                    <addrLine>Universität Bielefeld</addrLine>
                    <addrLine>Universitätsstraße 25</addrLine>
                    <addrLine>33615 Bielefeld</addrLine>
                    <addrLine>Deutschland</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Doctoral Consortium</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>KI</term>
                    <term>Science Fiction</term>
                    <term>Literaturwissenschaften</term>
                    <term>Politik</term>
                    <term>Digital Humanities</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <p>In einer Zeit, in der Künstliche Intelligenz (KI) zunehmend unseren Alltag und politische Debatten prägt, widmet sich diese Doktorarbeit der Frage, wie Science-Fiction-Literatur als kulturelle Wissensquelle zur Reflexion von Privatsphäre, Datenschutz und Überwachungssystemen dienen kann. Der Schwerpunkt liegt darauf, wie fiktionale Figuren in Science-Fiction KI-Überwachung wahrnehmen und mit diesen Systemen interagieren, um zu zeigen, wie spekulative Fiktion gesellschaftliche und kulturelle Diskurse widerspiegelt. Durch einen transkulturellen Vergleich der USA, der EU und Russlands sollen Unterschiede in der kulturellen Akzeptanz und Kritik solcher Technologien beleuchtet werden. Science-Fiction inspiriert nicht nur die technologische Entwicklung von KI (Dillon &amp; Schaffer-Goddard, 2023), sondern regt auch ethisches Bewusstsein und kulturelle Reflexionen an (Hudson et al., 2021; Dolan, 2020; Cave et al., 2019; Cave et al., 2020; Cave &amp; Dihal, 2023). Werke wie George Orwells 
                <hi rend="italic">1984</hi> oder William Gibsons 
                <hi rend="italic">Neuromancer</hi> befassen sich explizit und implizit mit KI-Überwachung und Privatsphäre, doch diese Themen wurden in der akademischen Literatur bisher nur wenig untersucht. Während viele Studien rechtliche und technologische Aspekte von KI-Überwachung behandeln (Zuboff, 2019; Lyon, 2018), rückt dieses Projekt die kulturellen und narrativen Dimensionen in den Vordergrund. Der transkulturelle Ansatz ermöglicht es, die Art und Weise zu analysieren, wie unterschiedliche kulturelle Werte – etwa Individualismus in den USA oder Kollektivismus in Russland (Bellman et al., 2004; Hofstede, 1980) – die Darstellung von Privatsphäre und Überwachung in der Literatur prägen.
            </p>
            <p>Erstens wird analysiert, wie KI-Überwachungssysteme in der Science-Fiction dargestellt werden und welche sozialen und kulturellen Kontexte sie widerspiegeln. Hierfür werden Foucaults Theorie der Überwachung (1977) und Jasanoff und Kims Konzept der soziotechnischen Imaginationen (2015) als theoretische Grundlage herangezogen, um die narrativen und symbolischen Mechanismen der Texte zu untersuchen. Zweitens erfolgt ein transkultureller Vergleich, der Gemeinsamkeiten und Unterschiede in der Darstellung von KI-Überwachung zwischen den USA, Russland und der EU mithilfe von Bakhtins „Dialogismus“ (1981) und Kristevas „Intertextualität“ (1969), um die kulturellen und historischen Kontexte der Narrative zu analysieren. Drittens sollen diese literarischen Darstellungen mit aktuellen Datenschutzregelungen wie der DSGVO (EU), der Privatsphärendebatte in den USA (Fazlioglu, 2020) und den Überwachungspraktiken in Russland (Pallin, 2017) verglichen werden, um die Wechselwirkungen zwischen spekulativer Fiktion und politischem Kontext zu untersuchen.</p>
            <p>Die Methodik kombiniert qualitative Analysen mit computergestützten Verfahren. In der ersten Phase wird ein Korpus von maximal 30 Science-Fiction-Werken zusammengestellt, die sich auf KI-Überwachung konzentrieren und kulturell sowie politisch repräsentativ für die untersuchten Regionen sind. Für die Analyse wird eine Mischung aus „close reading“ und „distant reading“ angewandt. Das Distant Reading wird mithilfe des Privacy-Wörterbuchs von Vasalou et al. (2011) spezifische Textpassagen identifiziert werden, die sich mit Privatsphäre und Überwachung befassen. Diese Passagen werden anschließend im Close Reading in den Kontext des Gesamtwerks eingebettet. Ziel ist es, sprachliche Muster zu identifizieren und zu analysieren, wie Privatsphäre thematisiert wird und wie die literarische Sprache im Vergleich zu politischen Diskursen genutzt wird. </p>
            <p>Das Close Reading mithilfe von Jonathan Cullers Literaturtheorie (2007) und Faircloughs Kritischen Diskursanalyse (1992) durchgeführt. Mithilfe von Foucaults Überwachungstheorie werden diese Passagen kategorisiert, etwa danach, ob die KI direkte Kontrolle ausübt und Widerstand provoziert oder ob Kontrolle internalisiert ist, wie im metaphorischen Panoptikum. Zudem wird untersucht, ob die KI als staatlich kontrolliertes System, unternehmensgesteuerte Technologie oder metaphorische Präsenz dargestellt wird und welche gesellschaftlichen Ängste dies reflektiert. Ziel ist es, die Darstellung von Kontrolle und Privatsphärenverletzungen in der Science-Fiction zu analysieren. Dabei werden Diskurse untersucht, die etwa Charaktere als machtlos oder widerstandsfähig gegenüber Überwachungssystemen beschreiben. Ebenso werden die Sprache, Metaphern und Symbole analysiert, die zur Beschreibung von KI-Überwachung verwendet werden. Diese Diskurse werden in ihren sozio-kulturellen und historischen Kontext eingeordnet, um zu verstehen, wie verschiedene Länder, wie Russland und die USA, KI-Überwachung unterschiedlich kritisch reflektieren.</p>
            <p>Die abschließende Phase umfasst eine vergleichende Analyse, eine Kontextualisierung, der literarischen Ergebnisse mit aktuellen politischen Dokumenten und Datenschutzrichtlinien, wie sie von der OECD, der OSTP (USA), Roskomnadzor (Russland) und dem EU-Parlament zwischen 2025 und 2028 herausgegeben werden. Inspiriert von Dillon und Craigs „Storylistening“ (2022) wird untersucht, wie literarische Darstellungen von KI-Überwachung mit zeitgenössischen Datenschutzrichtlinien in Beziehung stehen. Ziel ist es, die kognitiven und kollektiven Funktionen dieser Darstellungen zu analysieren und ihren Einfluss auf gesellschaftliche Identitäten und politische Debatten zu diskutieren.</p>
            <p>Die Ergebnisse des Projekts sollen zeigen, wie kulturelle Unterschiede die Wahrnehmung von KI-Überwachung prägen und wie spekulative Fiktion Debatten über KI-Governance, Ethik und Datenschutz bereichern kann. Das Projekt diskutiert, wie literarische Narrative als Werkzeuge für gesellschaftliche und politische Reflexion genutzt werden können und welchen Einfluss sie auf das Verständnis von Überwachung und Privatsphäre haben.</p>
            <p>Die Kritikpunkte aus den Gutachten wurden in der überarbeiteten Version berücksichtigt, insbesondere durch eine stärkere Fokussierung des Projektrahmens. Anstelle einer allgemeinen Untersuchung von Mensch-KI-Interaktionen konzentriert sich das Projekt nun explizit auf die menschliche Wahrnehmung von KI-Überwachung und die Verletzung der Privatsphäre durch KI-Technologien. Diese thematische Eingrenzung erlaubt eine präzisere Definition der Analysekategorien und der Suchbegriffe für das Distant Reading, das mithilfe von Vasalou et al.s Privacy-Wörterbuch (2011) durchgeführt wird. Dabei wurde jedoch auch die Einschränkung akzeptiert, dass die analysierten Texte für das Distan Reading in englischer Übersetzung vorliegen müssen.</p>
            <p>Die Methodologie der Analysen wurde stärker in etablierten literaturwissenschaftlichen Traditionen verankert, um eine tiefere theoretische Fundierung zu gewährleisten. Die Auswahl der Länder – USA, EU und Russland – ist mit Blick auf das Thema Privatsphäre besser begründet, da diese Regionen nicht nur Vorreiter in der KI-Entwicklung sind, sondern auch unterschiedliche kulturelle Wahrnehmungen von Privatsphäre (Bellman et al., 2004) und divergierende rechtliche Rahmenbedingungen aufweisen. Fiero und Beier (2022) haben dieselben Länder bereits für eine vergleichende Analyse der Regulierung von KI und Privatsphäre im rechtlichen Diskurs herangezogen, was die Relevanz dieser Auswahl unterstreicht. Die Einbeziehung Chinas wurde in Betracht gezogen, da es ebenfalls ein Vorreiter in der KI ist und eine besondere kulturelle Wahrnehmung der Privatsphäre aufzeigt (Hua und Wang, 2023), erscheint jedoch aufgrund sprachlicher und zugangstechnischer Hürden unpraktikabel.</p>
            <p>Die Methodologie und der analytische Rahmen für den politischen Diskurs müssen weiterhin präzisiert werden. Allerdings wurde durch die Eingrenzung des Projektthemas – von KI im politischen Diskurs allgemein auf KI-Überwachung und Privatsphäre – bereits ein zentraler Fokus geschaffen. Beim Doctoral Consortium werde ich den Analyseprozess durch konkrete Fallbeispiele visualisieren, um die Verbindung zwischen theoretischem Ansatz und praktischer Umsetzung klar darzustellen.</p>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliographie</head>
                    <bibl><hi rend="bold">Bakhtin, Mikhail</hi>. 
                        <hi rend="italic">The Dialogic Imagination</hi>. Austin: University of Texas Press, 1981.
                    </bibl>
                    <bibl><hi rend="bold">Bellman, Steven, Eric J. Johnson, Stephen J. Kobrin und Gerald L. Lohse</hi>. „International Differences in Information Privacy Concerns: A Global Survey of Consumers.“ 
                        <hi rend="italic">The Information Society</hi> 20, Nr. 5 (2004): 313–324. 
                        <ref target="https://doi.org/10.1080/01972240490507956">https://doi.org/10.1080/01972240490507956</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Cave, Stephen, Kanta Dihal und Sarah Dillon</hi>. 
                        <hi rend="italic">AI Narratives: A History of Imaginative Thinking about Intelligent Machines</hi>. Oxford: Oxford University Press, 2020.
                    </bibl>
                    <bibl><hi rend="bold">Cave, Stephen, und Kanta Dihal</hi>. 
                        <hi rend="italic">Imagining AI: How the World Sees Intelligent Machines</hi>. Oxford: Oxford University Press, 2023.
                    </bibl>
                    <bibl><hi rend="bold">Cave, Stephen und Kanta Dihaly</hi>. „Hopes and Fears for Intelligent Machines in Fiction and Reality.“ 
                        <hi rend="italic">Nature Machine Intelligence</hi> 1 (2019): 74–78. 
                        <ref target="https://doi.org/10.1038/s42256-019-0020-9">https://doi.org/10.1038/s42256-019-0020-9</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Culler, Jonathan D</hi>. 1997. 
                        <hi rend="italic">The Literary in Theory</hi>. Stanford, CA: Stanford University Press. Nachdruck 2007.
                    </bibl>
                    <bibl><hi rend="bold">Dillon, Sarah, und Claire Craig</hi>. 
                        <hi rend="italic">Storylistening: Narrative Evidence and Public Reasoning</hi>. Cambridge: Cambridge University Press, 2022.
                    </bibl>
                    <bibl><hi rend="bold">Dillon, Sarah, und Julia Schaffer-Goddard</hi>. „What AI Researchers Read: The Role of Literature in Artificial Intelligence Research.“ 
                        <hi rend="italic">Interdisciplinary Science Reviews</hi> 48, Nr. 1 (2023). 
                        <ref target="https://doi.org/10.1080/03080188.2022.2079214">https://doi.org/10.1080/03080188.2022.2079214</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Dolan, Timothy</hi>. „Science Fiction as Moral Allegory.“ 
                        <hi rend="italic">Journal of Futures Studies</hi> 24, Nr. 3 (März 2020): 105–112.
                    </bibl>
                    <bibl><hi rend="bold">Edmond, Jennifer, Vera Yakupova und Erik Ketzan</hi>. „A Tyrannical Societal Something: Drawing Lessons for Twenty-First-Century ‘Privacy-Protecting’ Technology from Long Nineteenth-Century Literature.“ 
                        <hi rend="italic">Interdisciplinary Science Reviews</hi> 49, Nr. 2 (2024): 189–207. 
                        <ref target="https://doi.org/10.1177/03080188241258422">https://doi.org/10.1177/03080188241258422</ref>.
                    </bibl>
                    <bibl><hi rend="bold">European Parliament</hi>. 
                        <hi rend="italic">Artificial Intelligence</hi>. Zugriff am 2. Dezember 2024. 
                        <ref target="https://www.europarl.europa.eu/topics/en/topic/artificial-intelligence">https://www.europarl.europa.eu/topics/en/topic/artificial-intelligence</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Fairclough, Norman</hi>. 
                        <hi rend="italic">Discourse and Social Change</hi>. Cambridge: Polity Press, 1992.
                    </bibl>
                    <bibl><hi rend="bold">Fazlioglu, Muge</hi>. „The United States and the EU’s General Data Protection Regulation.“ In 
                        <hi rend="italic">Data Protection Around the World</hi>, 231–48. 2020.
                    </bibl>
                    <bibl><hi rend="bold">Fiero, Anna Wright, und Elena Beier</hi>. „New Global Developments in Data Protection and Privacy Regulations: Comparative Analysis of European Union, United States, and Russian Legislation.“ 
                        <hi rend="italic">Stanford Journal of International Law</hi> 58, Nr. 2 (Sommer 2022): 151–192.
                    </bibl>
                    <bibl><hi rend="bold">Foucault, Michel</hi>. 
                        <hi rend="italic">Discipline and Punish: The Birth of the Prison</hi>. New York: Pantheon, 1977.
                    </bibl>
                    <bibl><hi rend="bold">Hofstede, Geert</hi>. 
                        <hi rend="italic">Culture and Organizations: Software of the Mind</hi>. London: McGraw-Hill, 1980.
                    </bibl>
                    <bibl style="text-align: left;"><hi rend="bold">Hua, Xi, und Jian Wang</hi>. "Cultural Differences in Privacy Protection: A Case Study of DiDi." 
                        <hi rend="italic">Journal of International Business Studies</hi>, 2023. https://doi.org/10.48009/2_iis_2023_127.
                    </bibl>
                    <bibl><hi rend="bold">Hudson, Adam D., Ed Finn und Rhiannon Wylie</hi>. „What Can Science Fiction Tell Us About the Future of Artificial Intelligence Policy?“ 
                        <hi rend="italic">AI &amp; Society</hi> 38 (2023): 197–211. 
                        <ref target="https://doi.org/10.1007/s00146-021-01273-2">https://doi.org/10.1007/s00146-021-01273-2</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Jasanoff, Sheila, und Sang-Hyun Kim, Hrsg.</hi> 
                        <hi rend="italic">Dreamscapes of Modernity: Sociotechnical Imaginaries and the Fabrication of Power</hi>. Chicago: University of Chicago Press, 2015.
                    </bibl>
                    <bibl><hi rend="bold">Kristeva, Julia</hi>. 
                        <hi rend="italic">Desire in Language: A Semiotic Approach to Literature and Art</hi>. Hrsg. von Leon S. Roudiez, übersetzt von Thomas Gora, Alice Jardine und Leon S. Roudiez. New York: Columbia University Press, 1980.
                    </bibl>
                    <bibl><hi rend="bold">Lyon, David</hi>. 
                        <hi rend="italic">Surveillance Studies: An Overview</hi>. Cambridge: Polity Press, 2007.
                    </bibl>
                    <bibl><hi rend="bold">Moretti, Franco</hi>. 2000. "Conjectures on World Literature." 
                        <hi rend="italic">New Left Review</hi> 1 (1): 54-68. 
                        <ref target="https://iedamagri.files.wordpress.com/2017/01/franco-moretti.pdf">
                            <hi rend="underline">https://iedamagri.files.wordpress.com/2017/01/franco-moretti.pdf</hi>
                        </ref>.
                    </bibl>
                    <bibl><hi rend="bold">OECD</hi>. „Privacy and Artificial Intelligence Search Results.“ OECD, 2024. 
                        <ref target="https://www.oecd.org/content/oecd/en/search.html?q=privacy+artificial+intelligence&amp;orderBy=mostRelevant&amp;page=0">https://www.oecd.org/content/oecd/en/search.html?q=privacy+artificial+intelligence&amp;orderBy=mostRelevant&amp;page=0</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Pallin, Carolina Vendil</hi>. „Internet Control through Ownership: The Case of Russia.“ 
                        <hi rend="italic">Post-Soviet Affairs</hi> 33, Nr. 1 (2017): 16–33. 
                        <ref target="https://doi.org/10.1080/1060586X.2015.1121712">https://doi.org/10.1080/1060586X.2015.1121712</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Vasalou, Asimina, Alastair J. Gill, Fadhila Mazanderani und Adam N. Joinson</hi>. „Privacy Dictionary: A New Resource for the Automated Content Analysis of Privacy.“ 
                        <hi rend="italic">Journal of the American Society for Information Science and Technology</hi> 62, Nr. 11 (2011): 2095–2105. 
                        <ref target="https://doi.org/10.1002/asi.21610">https://doi.org/10.1002/asi.21610</ref>.
                    </bibl>
                    <bibl><hi rend="bold">Zuboff, Shoshana</hi>. 
                        <hi rend="italic">The Age of Surveillance Capitalism</hi>. London: Profile Books, 2018.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
