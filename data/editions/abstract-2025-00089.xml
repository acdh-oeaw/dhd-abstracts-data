<?xml version="1.0" encoding="utf-8"?>
<TEI xml:id="BROOKSHIRE_Patrick_Daniel_Warum_wird_was_wie_klassifiziert_" xmlns="http://www.tei-c.org/ns/1.0">
<teiHeader>
<fileDesc>
<titleStmt>
<title type="full">
<title type="main">Warum wird was wie klassifiziert?</title>
<title type="sub">Scalable Reading + Explainable AI </title>
<title type="sub">am Beispiel historischer Lebensverläufe</title>
</title>
<author>
<persName>
<surname>Brookshire</surname>
<forename>Patrick Daniel</forename>
</persName>
<affiliation>Akademie der Wissenschaften und der Literatur | Mainz / Universität zu Köln, Deutschland</affiliation>
<email>Patrick.Brookshire@adwmainz.de</email>
<idno type="ORCID">0000-0002-5843-7577</idno>
</author>
</titleStmt>
<editionStmt>
<edition>
<date>2024-07-22T14:42:18.990460571</date>
</edition>
</editionStmt>
<publicationStmt>
<publisher>Bielefeld Computational Literary Studies Group</publisher>
<address>
<addrLine>Universität Bielefeld</addrLine>
<addrLine>Universitätsstraße 25</addrLine>
<addrLine>33615 Bielefeld</addrLine>
<addrLine>Deutschland</addrLine>
</address>
<publisher>Digital History</publisher>
<address>
<addrLine>Universität Bielefeld</addrLine>
<addrLine>Universitätsstraße 25</addrLine>
<addrLine>33615 Bielefeld</addrLine>
<addrLine>Deutschland</addrLine>
</address>
<publisher>Digital Linguistics Lab</publisher>
<address>
<addrLine>Universität Bielefeld</addrLine>
<addrLine>Universitätsstraße 25</addrLine>
<addrLine>33615 Bielefeld</addrLine>
<addrLine>Deutschland</addrLine>
</address>
<idno subtype="zenodo" type="url">https://zenodo.org/records/14943204</idno></publicationStmt>
<sourceDesc>
<p>Converted from an OASIS Open Document</p>
</sourceDesc>
</fileDesc>
<encodingDesc>
<appInfo>
<application ident="DHCONVALIDATOR" version="1.22">
<label>DHConvalidator</label>
</application>
</appInfo>
</encodingDesc>
<profileDesc>
<textClass>
<keywords n="category" scheme="ConfTool">
<term>Paper</term>
</keywords>
<keywords n="subcategory" scheme="ConfTool">
<term>Poster</term>
</keywords>
<keywords n="keywords" scheme="ConfTool">
<term>Scalable Reading</term>
<term>eXplainable AI</term>
<term>Historische Biographien</term>
<term>Sentimentanalyse</term>
</keywords>
<keywords n="topics" scheme="ConfTool">
<term>Entdeckung</term>
<term>Annotieren</term>
<term>Bereinigung</term>
<term>Visualisierung</term>
<term>Methoden</term>
</keywords>
</textClass>
</profileDesc>
</teiHeader>
<text>
<body>
<div rend="DH-Heading1" type="div1">
<head>Einleitung</head>
<p>Eine Klassifikation von Textabschnitten ist im DH-Kontext häufig „under construction“, da vorliegende Verfahren viele Varianten aufweisen, aber nicht domänen-spezifisch genug sind. Deshalb ist stets eine Evaluation mit dem konkreten Datensatz nötig. Zudem sind bei besonders kontextabhängigen Tasks, für die Sentimentanalysen ein verbreitetes Beispiel sind, Deep-Learning-Methoden performanter, dafür aber weniger interpretierbar als bspw. Lexikon-basierte Verfahren (Singh und Singh, 2021; Schmidt et al., 2022; Rebora et al., 2023). Eine mögliche Lösung sind Explainability-Modelle wie 
                    <hi rend="italic">LIME</hi> (Ribeiro et al., 2016), 
                    <hi rend="italic">SHAP</hi> (Lundberg und Lee, 2017) oder 
                    <hi rend="italic">Transformer-Explainability</hi> (Chefer et al., 2021). Allerdings erfordern diese mitunter mehr Rechenleistung als das Finetuning eines Klassifikationsmodells (Brookshire und Reiter, 2024, 99f.). Nichtsdestotrotz lassen sie sich in einen an das Scalable Reading (vgl. Weitin 2017) angelehnten Workflow einbinden, mit dem Analysen iterativ in ihrer Validität verbessert werden können. Dieser wird im folgenden am Beispiel der Untersuchung von Polaritätsverläufen illustriert, welche sich bei biographischen Daten anbietet (Dennis-Henderson et al., 2020, 96; Koncar et al., 2020, 8–10; Faull und McGuire, 2022, 143f.).
                </p>
</div>
<div rend="DH-Heading1" type="div1">
<head>Biographiekorpus</head>
<p>In einer Pilotstudie werden Daten des retrodigitalisierten biographischen Nachschlagewerks 
                    <hi rend="italic">Allgemeine Deutsche Biographie</hi> (Reinert et al., 2015) nachgenutzt. Es umfasst insgesamt über 25.000 Artikel zu Personen, die vor 1900 geboren sind. Davon werden hier knapp 3.600 Personen, die zwischen 1750 und 1850 geboren und gestorben sind, berücksichtigt. Diese Zahl wurde durch ein teil-randomisiertes Subsampling auf 360 reduziert, welches sicherstellt, dass jeder Text mind. 10 Sätze umfasst. Desweiteren erfolgte als einziger Preprocessing-Schritt eine Satztokenisierung mit 
                    <hi rend="italic">stanza</hi> (Qi et al., 2020).
                </p>
</div>
<div rend="DH-Heading1" type="div1">
<head>Methodologie und inhaltliche Erkenntnisse</head>
<p>Aus technischer Sicht umfasst das vorgestellte Verfahren die fünf Module 
                    <hi rend="italic">Klassifikation</hi>, 
                    <hi rend="italic">Ordinal-Transformation</hi>, 
                    <hi rend="italic">Segmentierung</hi>, 
                    <hi rend="italic">Aggregierung</hi> und 
                    <hi rend="italic">Erklärung</hi>, wobei die ersten vier einem Distant-Reading-Ansatz folgen. So lassen sich etwa Polaritätsverläufe der zu untersuchenden historischen Biographien folgendermaßen operationalisieren: Zunächst weist ein passendes 
                    <hi rend="bold">Klassifikations</hi>-Modell (Brookshire und Reiter, 2024) den Sätzen automatisch Sentiment-Labels zu. Anschließend werden diese nominalen Kategorien durch ein Mapping (negativ: -1, neutral: 0, positiv: 1) in ordinale (= Polarität) 
                    <hi rend="bold">transformiert</hi>. Im dritten Schritt erfolgt eine 
                    <hi rend="bold">Segmentierung</hi> in bspw. gleichlange Textabschnitte (Steps), um Texte unterschiedlicher Länge miteinander vergleichen zu können. Abschließend werden die Werte pro Segment 
                    <hi rend="bold">aggregiert</hi> – üblicherweise mit Mittelwerten, was letztlich eine Parametrisierung ist –, um einen Gesamt-Verlauf der 360 Biographien zu erzeugen:
                </p>
<p>
<figure>
<graphic url="Pictures/44b11a03efa630f70c589adf71c61285.png"/>
<head>Abb. 1: Durchschnittlicher Polaritätsverlauf mit Hervorhebung des neutralen Bereichs</head>
</figure>
</p>
<p>Durch die Markierung des neutralen Bereichs mit gängigen Schwellenwerten (± 0,05; vgl. Hutto und Gilbert, 2014, 224) wird deutlich, dass das Korpus einen leicht positiven Trend mit nur wenigen Schwankungen aufweist. Allerdings zeichnet ein Reinzoomen im Sinne des Scalable Readings auf 36 zufällig ausgewählte Einzelbiographien ein deutlich anderes Bild:</p>
<p>
<figure>
<graphic url="Pictures/3cd768b211fd5d9499a62c84832e0ad8.png"/>
<head>Abb. 2: 36 Einzel-Polaritätsverläufe mit Hervorhebung des neutralen Bereichs</head>
</figure>
</p>
<p>Die Variabilität ist bei einem individuellen Genre wie Biographien nicht überraschend, aber bei der Analyse größerer Datenmengen wegen der Tendenz von Durchnittswerten zum neutralen Bereich (vgl. Jockers, 2015) nur durch Skalenwechsel zu beobachten.</p>
<p>Aufgrund der nicht perfekten automatischen Annotationen kann auch diese Einzelansicht mitunter täuschen, weshalb im vorgelegten Verfahren eine am Close-Reading orientierte 
                    <hi rend="bold">Explainability</hi>-Schleife als fünftes Modul vorgesehen ist. In dieser kann bspw. der starke Abfall in den negativen Bereich bei 75% der Biographie der Person mit der ID 
                    <hi rend="italic">sfz80512</hi> erklärt werden.
                </p>
<p>
<figure>
<graphic url="Pictures/f59132cac71be331bb42a334a9447a8b.png"/>
<head>Abb. 3: Einfärbung der Auswirkung einzelner Subwordtokens auf die Klassifikation</head>
</figure>
</p>
<p>So gehen die hier durch Farbsättigung visualisierten Ergebnisse des (aus Performance-Gründen gewählten) Explainability-Modells von Chefer et al. (2021) über die reinen Klassifikationswahrscheinlichkeiten hinaus. Denn sie illustrieren, dass die negativ-Labels auf Subword-Tokens wie „nur“, „muß“ und „Aufhebung“ zurückgehen, aber den gegebenen neutral formulierten philosophischen Abschnitt nur bedingt abbilden. In diesem Fall wäre also eine manuelle Bereinigung der entsprechenden Labels sinnvoll und dank der mitvisualisierten Position im Gesamtdatensatz durch Quellen-ID und Satznummer auch möglich. Zudem ist auch ein erneutes Finetuning mit diesen Datensätzen denkbar.</p>
</div>
<div rend="DH-Heading1" type="div1">
<head>Fazit und Ausblick</head>
<p>Das vorgestellte Verfahren zeigt, wie sich Fehlklassifikationen, die für nachgelagerte Analyseschritte besonders relevant sind, durch eine Kombination aus Scalable-Reading- und Explainability-Ansätzen gezielt identifizieren und ggf. manuell korrigieren lassen. Denn zur Steigerung der Validität ist es durch Aggregierungsschritte nicht immer nötig, alle Datensätze zu bereinigen – und je nach personeller und technischer Ausstattung auch nicht immer umsetzbar. Auch wenn das Verfahren hier am Beispiel von Sentimentwerten illustriert wurde, ist es grundsätzlich auf beliebige Klassifikationsaufgaben anwendbar. Daher ist derzeit ein entsprechender Ausbau in Richtung nominal-skalierter Kategorien „under construction“. Zudem ist angedacht, die Modularisierung so konsequent umzusetzen, dass künftig neben beliebigen Klassifikationsmodellen auch bei den übrigen Modulen beliebige Komponenten angedockt werden können, um dem Variantenreichtum gerecht zu werden.</p>
</div>
</body>
<back>
<div type="bibliogr">
<listBibl>
<head>Bibliographie</head>
<bibl>
<hi rend="bold">Brookshire, Patrick </hi>
<hi rend="bold">D. </hi>
<hi rend="bold">und Nils Reiter.</hi> 2024. „Modeling Moravian Memoirs: Ternary Sentiment Analysis in a Low Resource Setting“. In 
                        <hi rend="italic">Proceedings of the 8th Joint SIGHUM </hi>
<hi rend="italic">Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</hi>, 91–100. https://aclanthology.org/2024.latechclfl-1.10.
                    </bibl>
<bibl>
<hi rend="bold">Chefer, Hila, Shir Gur und Lior Wolf.</hi> 2021. „Transformer Interpretability Beyond Attention Visualization“. In 
                        <hi rend="italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition</hi>, 782–791. https://doi.org/10.1109/CVPR46437.2021.00084.
                    </bibl>
<bibl>
<hi rend="bold">Dennis-Henderson, Ashley, Matthew Roughan, Lewis Mitchell und Jonathan Tuke.</hi> 2020. „Life Still Goes on: Analysing Australian WW1 Diaries through Distant Reading“. In 
                        <hi rend="italic">Proceedings of the The 4th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</hi>, 90–104. https://aclanthology.org/2020.latechclfl-1.11/.
                    </bibl>
<bibl>
<hi rend="bold">Faull, Katherine und Michael McGuire.</hi> 2022. „Analyzing Moravian Feelings Using Computational Methods to Ask Questions about Norms and Sentiments in Eighteenth-Century Moravian Lebensläufe“. 
                        <hi rend="italic">Journal of Moravian History</hi> 22 (2): 125–149. https://doi.org/10.5325/jmorahist.22.2.0125.
                    </bibl>
<bibl>
<hi rend="bold">Hutto, </hi>
<hi rend="bold">Clayton</hi>
<hi rend="bold"> J. und Eric Gilbert.</hi> 2014. „VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text“. In 
                        <hi rend="italic">Proceedings of the Eighth International AAAI Conference on Weblogs and Social Media</hi>, 216–222. https://doi.org/10.1609/icwsm.v8i1.14550.
                    </bibl>
<bibl>
<hi rend="bold">Jockers, Matthew </hi>
<hi rend="bold">L.</hi> 2015. „Revealing Sentiment and Plot Arcs with the Syuzhet Package“ https://www.matthewjockers.net/2015/02/02/syuzhet/ (zugegriffen: 22.07.2024).
                    </bibl>
<bibl>
<hi rend="bold">Koncar, Philipp, Alexandra Fuchs, Elisabeth Hobisch, Bernhard C. Geiger, Martina Scholger und Denis Helic.</hi> 2020. „Text Sentiment in the Age of Enlightenment: An Analysis of Spectator Periodicals“. 
                        <hi rend="italic">Applied Network Science</hi> 5 (1): 1–32. https://doi.org/10.1007/s41109-020-00269-z.
                    </bibl>
<bibl>
<hi rend="bold">Lundberg, Scott M. und Su-In Lee.</hi> 2017. „A Unified Approach to Interpreting Model Predictions“. 
                        <hi rend="italic">Advances in Neural Information Processing Systems</hi> 30. https://papers.nips.cc/paper_files/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html.
                    </bibl>
<bibl>
<hi rend="bold">Qi, Peng, Yuhao Zhang, Yuhui Zhang, Jason Bolton und Christopher D. Manning.</hi> 2020. „Stanza: A Python Natural Language Processing Toolkit for Many Human Languages“. In 
                        <hi rend="italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</hi>, 101–108. https://doi.org/10.18653/v1/2020.acl-demos.14.
                    </bibl>
<bibl>
<hi rend="bold">Rebora, Simone, Marina Lehmann, Anne Heumann, Wei Ding und Gerhard Lauer.</hi> 2023. „Comparing ChatGPT to Human Raters and Sentiment Analysis Tools for German Children’s Literature“. In 
                        <hi rend="italic">Proceedings of the Computational Humanities Research Conference</hi>, 333–343. https://ceur-ws.org/Vol-3558/paper3340.pdf.
                    </bibl>
<bibl>
<hi rend="bold">Reinert, Matthias, Maximilian Schrott und Bernhard Ebneth.</hi> 2015. „From Biographies to Data Curation – the Making of www.deutsche-biographie.de“. In 
                        <hi rend="italic">Proceedings of the First Conference on Biographical Data in a Digital World</hi>, 13–19. https://ceur-ws.org/Vol-1399/paper3.pdf.
                    </bibl>
<bibl>
<hi rend="bold">Ribeiro, Marco Tulio, Sameer Singh und Carlos Guestrin.</hi> 2016. „‚Why Should I Trust You?‘: Explaining the Predictions of Any Classifier“. In 
                        <hi rend="italic">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</hi>, 1135–1144. https://doi.org/10.1145/2939672.2939778.
                    </bibl>
<bibl>
<hi rend="bold">Schmidt, Thomas, Katrin Dennerlein und Christian Wolff.</hi> 2022. „Evaluation computergestützter Verfahren der Emotionsklassifikation für deutschsprachige Dramen um 1800“. In 
                        <hi rend="italic">8. Tagung des Verbands Digital Humanities im deutschsprachigen Raum </hi>
<hi rend="italic">e. V</hi>. https://doi.org/10.5281/zenodo.6328169.
                    </bibl>
<bibl>
<hi rend="bold">Singh, Loitongbam Gyanendro und Sanasam Ranbir Singh.</hi> 2021. „Empirical Study of Sentiment Analysis Tools and Techniques on Societal Topics“. 
                        <hi rend="italic">Journal of Intelligent Information Systems</hi> 56 (2): 379–407. https://doi.org/10.1007/s10844-020-00616-7.
                    </bibl>
<bibl>
<hi rend="bold">Weitin, Thomas.</hi> 2017. „Scalable Reading“. 
                        <hi rend="italic">Zeitschrift für Literaturwissenschaft und Linguistik</hi> 47 (1): 1–6. https://doi.org/10.1007/s41244-017-0048-4.
                    </bibl>
</listBibl>
</div>
</back>
</text>
</TEI>