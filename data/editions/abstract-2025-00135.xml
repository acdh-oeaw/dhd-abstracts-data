<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="FL_H_Marie_Das_Projekt_CompAnno__Comparative_Annotation_to_E">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Das Projekt CompAnno: Comparative Annotation to Explore and Explain Text Similarities</title>
                <author>
                    <persName>
                        <surname>Flüh</surname>
                        <forename>Marie</forename>
                    </persName>
                    <affiliation>Universität Hamburg, Deutschland</affiliation>
                    <email>marie.flueh@uni-hamburg.de</email>
                    <idno type="ORCID">0000-0002-1707-284X</idno>
                </author>
                <author>
                    <persName>
                        <surname>Nantke</surname>
                        <forename>Julia</forename>
                    </persName>
                    <affiliation>Universität Hamburg, Deutschland</affiliation>
                    <email>julia.nantke@uni-hamburg.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Pagel</surname>
                        <forename>Janis</forename>
                    </persName>
                    <affiliation>Universität zu Köln, Deutschland</affiliation>
                    <email>jpagel1@uni-koeln.de</email>
                </author>
                <author>
                    <persName>
                        <surname>Reiter</surname>
                        <forename>Nils</forename>
                    </persName>
                    <affiliation>Universität zu Köln, Deutschland</affiliation>
                    <email>nils.reiter@uni-koeln.de</email>
                    <idno type="ORCID">0000-0003-3193-6170</idno>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2023-06-13T14:32:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Bielefeld Computational Literary Studies Group</publisher>
                <address>
                    <addrLine>Universität Bielefeld</addrLine>
                    <addrLine>Universitätsstraße 25</addrLine>
                    <addrLine>33615 Bielefeld</addrLine>
                    <addrLine>Deutschland</addrLine>
                </address>
                <publisher>Digital History</publisher>
                <address>
                    <addrLine>Universität Bielefeld</addrLine>
                    <addrLine>Universitätsstraße 25</addrLine>
                    <addrLine>33615 Bielefeld</addrLine>
                    <addrLine>Deutschland</addrLine>
                </address>
                <publisher>Digital Linguistics Lab</publisher>
                <address>
                    <addrLine>Universität Bielefeld</addrLine>
                    <addrLine>Universitätsstraße 25</addrLine>
                    <addrLine>33615 Bielefeld</addrLine>
                    <addrLine>Deutschland</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Poster</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>Computational Literary Studies</term>
                    <term>Intertextualität</term>
                    <term>Figurenanalyse</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>Beziehungsanalyse</term>
                    <term>Annotieren</term>
                    <term>Literatur</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div type="div1" rend="DH-Heading1">
                <head>1. Comparative Annotation to Explore and Explain Text Similarities (CompAnno)</head>
            <p>Das DFG-Projekt CompAnno entwickelt einen vergleichenden Annotationsworkflow zur computergestützten Detektion und Klassifizierung von literarischen Textähnlichkeiten am Beispiel von Figureneigenschaften als einer Kategorie, die für die Gestaltung literarischer Erzähltexte und für die Interpretation intertextueller Beziehungen zentral ist (Müller 1991:101). Der Workflow für eine computergestützte Untersuchung von Textähnlichkeit soll so gestaltet sein, dass er über die Erkennung von text-reuse hinausgeht und nicht auf ein festes Korpus bezogen ist. Gleichzeitig greifen wir mit der vergleichenden Annotation eine literaturwissenschaftliche Basismethode auf (Unsworth 2000, Epple et al. 2020:7) und entwickeln einen neuen Weg für die Arbeit mit interpretativen Kategorien.</p>
            </div>
            <div type="div1" rend="DH-Heading2"><head>2. Annotationsaufgaben</head>
            <p>Wir arbeiten mit vier Annotatorinnen, wobei die Annotationsaufgaben zur Annotation von Figureneigenschaften ineinandergreifen. Die Annotatorinnen sind alle Germanistik- und Linguistikstudentinnen. Da Figuren in der Regel zu Beginn eines Textes eingeführt werden, ist hier mit besonders zahlreichen Eigenschaften zu rechnen. Deshalb werden in unterschiedlichen Annotationsphasen jeweils die Anfangspassagen (circa 20.000 Tokens) aus verschiedenen Prosatexten aus 
                <hi rend="italic">d-Prose</hi> (1870–1920, Gius et al. 2021) annotiert.</p>
            </div>
            <div type="div2" rend="DH-Heading2"><head>2.1 Explorative Annotation mit CATMA</head>
            <p>Um einen differenzierten und spezifischen Blick auf das Phänomen zu erlangen 
                <hi rend="background(white)" xml:space="preserve">und </hi>eine möglichst große Bandbreite an Figureneigenschaften zu ermitteln, wird zunächst explorativ annotiert (vgl. Pagel et al. 2020: 
                <hi rend="background(white)">127)</hi>. Die qualitative Auswertung der Annotationsdaten bildet die Grundlage für Richtlinien für die manuelle Annotation von Figureneigenschaften.
           </p> </div>
            <div type="div2" rend="DH-Heading2"><head>2.2 Automatisierungsorientierte Annotation</head>
            <p>Figureneigenschaften werden erst manuell ermittelt und kategorisiert. Auf Grundlage der Guidelines ist jede Annotatorin für die Analyse einer ausgewählten Kategorie zuständig. In Diskussionsrunden werden die Annotationsdaten besprochen und angepasst. Darauf aufbauend wird ein Ranking der Ähnlichkeiten erstellt, das zum Trainieren oder Prompten eines maschinellen Lernsystems bzw. großen Sprachmodells verwendet wird. Ziel dieses Modells ist die automatische Erkennung von Stellen, an denen eine Figureneigenschaft vorkommt, sowie die Kategorie der Figureneigenschaft, so dass eine vergleichende Annotation Sinn ergibt.</p>
            </div>
            <div type="div2" rend="DH-Heading2"><head>2.3 Vergleichende Annotation mit PhiTag</head>
            <p>Im Gegensatz zu etablierten Annotationsansätzen beruht die vergleichende Annotation auf der gleichzeitigen Betrachtung mehrerer Textausschnitte: Auf Grundlage von Richtlinien für die vergleichende Annotation von Figureneigenschaften werden den Annotatorinnen jeweils zwei Textabschnitte vorgelegt, zu denen dann die ihnen enthaltenen Figureneigenschaften vergleichend zu annotieren sind. Benutzt wird hierzu die Webanwendung 
                <hi rend="italic">PhiTag</hi> (Schlechtweg, 
                <hi rend="background(white)">Kotchourko o.D.)</hi>, die ursprünglich für die Annotation semantischer Ähnlichkeiten entwickelt wurde (
                <hi rend="background(white)">Schlechtweg et al. 2020)</hi> und durch ihre quelloffene und modular erweiterbare Schnittstelle eine individuelle, projektspezifische Erweiterung für das vergleichende Annotieren unterstützt (s. Abb. 1). 
            </p>
            <p>Im weiteren Projektverlauf sollen die vergleichenden Annotationen dazu benutzt werden, die zuvor genannten intertextuellen Beziehungen zu beleuchten.</p>
            <figure>
                <graphic n="1001" width="16.51cm" height="10.089444444444444cm" url="Pictures/abaaabd854dbe0fd7b683a5d2e29b624.png" rend="inline"/>
                
                <head>Abbildung 1: Screenshot eines zu annotierenden Textpaares in 
                    <hi rend="italic">PhiTag</hi> mit Angabe von Unterkategorie und Referenzgröße; Textpaare stammen aus unterschiedlichen Texten, zum Vergleich vorgesehene Eigenschaften (rot markiert) stammen aus derselben Unterkategorie und werden auf eine Skala von “Gegensatz” zu “identisch” verortet</head>
            </figure>
            </div>
            <div type="div1" rend="DH-Heading1"><head>3. Erste Ergebnisse</head>
            <p>Bisher entstandene Teilergebnisse sind Annotationsrichtlinien, Einblicke in die Annotationspraxis, qualitative und quantitative Einblicke in die Darstellung und Verteilung von Figureneigenschaften sowie erste Automatisierungsversuche.</p>
            </div>
            <div type="div2" rend="DH-Heading2"><head>3.1 Guidelines zur manuellen Annotation und zur vergleichenden Annotation von Figureneigenschaften</head>
            <p>Aus der induktiven Auswertung der explorativen Annotationsphase, in der unter Einbezug etablierter Figurenkonzepte (Forster 1949, Hansen 2000, Jannidis 2004) vor allem konzeptuelle Fragestellungen im Fokus standen, ergeben sich fünf bzw. sechs Oberkategorien, die häufig für die Beschreibung literarischer Figuren verwendet werden und deshalb als Analysekategorien für die automatisierungsorientierte und vergleichende Annotation in Frage kommen (s. Abb. 2).</p>
            <figure>
                <graphic n="1002" width="12.752916666666666cm" height="9.564688888888888cm" url="Pictures/5e9e4c966d5f9b88c8d86ca0e5c6a107.png" rend="inline"/>
                <head>Abbildung 2: Schematischer Aufbau des Tagsets zur Annotation von Figureneigenschaften (mit Titeln der in den Guidelines detailliert definierten Ober- und Unterkategorien)</head>
            </figure>
            </div>
            <div type="div2" rend="DH-Heading2"><head>3.2 Quantitative und qualitative Auswertung der Annotationen und der Annotationsverfahren</head>
            <p>Bisher zeigt sich, dass Figuren vor allem über Rollen und Charaktereigenschaften näher beschrieben werden (s. Tabelle 1).</p>
            <table rend="rules">
                <head>Tabelle 1: Anzahl der Annotationen pro Kategorie in vier Beispieltexten</head>
                
                <row>
                    <cell style="text-align: left;">Kategorie</cell>
                    <cell style="text-align: left;">Annotationen</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Rolle</cell>
                    <cell style="text-align: left;">1206</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Charakter</cell>
                    <cell style="text-align: left;">328</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Alter</cell>
                    <cell style="text-align: left;">289</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Physiognomie</cell>
                    <cell style="text-align: left;">122</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Kleidung</cell>
                    <cell style="text-align: left;">77</cell>
                </row>
            </table>
            <p>Für jede Annotation legen die Annotatorinnen den Interpretationsaufwand auf einer Skala von sehr niedrig bis sehr hoch fest. Ausgehend von der Annahme, dass ein geringer Interpretationsgrad auf explizit im Text thematisierte Figureneigenschaften und ein hoher Interpretationsgrad auf implizite Figureneigenschaften hindeutet, fungiert er als Marker für den Grad der Explizitheit.</p>
            <figure>
                <graphic n="1003" width="11.617288888888888cm" height="6.6278138888888884cm" url="Pictures/afc5a438d6a81cb031e93a566da0b74f.png" rend="inline"/>
                <head>Abbildung 3: Interpretationsgrad für vier Beispieltexte im Überblick</head>
            </figure>
            <p>Bei der Auswertung eines Teils der Annotationsdaten zeigt sich, dass der Interpretationsgrad meistens als gering eingeschätzt wird. Dieser Befund ist als individuelle Annotationsentscheidung aufzufassen. Außerdem lässt sich schlussfolgern, dass Eigenschaften vor allem explizit erwähnt werden (s. Abb. 3) und implizite Eigenschaften eher ein Randphänomen darstellen. Ein niedriger Interpretationsgrad findet sich vor allem in den Kategorien “Kleidung”, “Alter” und “Physiognomie” und ein höherer in den Kategorien “Rolle” und “Charakter”.</p>
            <p>Eigenschaften, für die ein niedriger Interpretationsgrad angegeben wurde (explizite Eigenschaften), sind in allen Texten häufig. Sie sind ‚hochgradig intertextuell‘ und relativ generisch (bspw. “jung”, “schön” oder “groß”). Eigenschaften, die mit einem hohen Interpretationsgrad ausgezeichnet wurden, kommen in einzelnen Texten und in geringerer Anzahl vor. Implizite Eigenschaften scheinen individuell zu sein, können aber gerade deshalb eine spezifischere Verbindung zwischen zwei Texten markieren als die explizit-generischen Eigenschaften.</p>
            </div>
            <div type="div1" rend="DH-Heading1"><head>4. Ansätze zur Automatisierung</head>
            <p>Erste Pilotexperimente zur automatischen Klassifizierung von Figureneigenschaften zeigen, dass zwar schon moderat gute Ergebnisse mit relativ simplen Methoden zu erreichen sind, aber die Performanz noch ausbaufähig ist. Tabelle 2 zeigt die Durchschnittswerte für Precision, Recall und F1-Score für die Klassifikation von drei Modellen<ref n="1" target="ftn1"/> (BERT (Devlin et al. 2019), ELECTRA (Clark et al. 2020) und RoBERTa (Liu et al. 2019)) für den Task in Sätzen mit Figureneigenschaft die korrekte Kategorie zu nennen. Benutzt wurden vier Texte, die Daten wurden in 80 % Trainingsdaten und 20 % Testdaten aufgeteilt. Alle Modelle wurden für 40 Epochen fine-tuned, mit einer Learning Rate von 4e-5.
            </p>
            <p>Die Ergebnisse zeigen, dass die Klassifikation von Charaktereigenschaft, Physiognomie und Rolle mit ca. 60 % F1-Score im ersten Anlauf akzeptabel funktioniert, die Modelle jedoch Probleme haben, “Alter” und “Kleidung” richtig zu klassifizieren (16 bzw. 36 % F1-Score), außerdem ist die Precision für Rolle mit 6 % deutlich niedriger als für die anderen Kategorien.</p>
            <table rend="rules">
                <row>
                    <cell style="text-align: left;"/>
                    <cell style="text-align: left;">Precision</cell>
                    <cell style="text-align: left;">Recall</cell>
                    <cell style="text-align: left;">F1-Score</cell>
                    <cell style="text-align: left;">Instanzen</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Alter</cell>
                    <cell style="text-align: left;">0.25</cell>
                    <cell style="text-align: left;">0.12</cell>
                    <cell style="text-align: left;">0.16</cell>
                    <cell style="text-align: left;">11</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Charaktereigen-schaft</cell>
                    <cell style="text-align: left;">0.64</cell>
                    <cell style="text-align: left;">0.73</cell>
                    <cell style="text-align: left;">0.68</cell>
                    <cell style="text-align: left;">37</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Kleidung</cell>
                    <cell style="text-align: left;">0.34</cell>
                    <cell style="text-align: left;">0.38</cell>
                    <cell style="text-align: left;">0.36</cell>
                    <cell style="text-align: left;">13</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Physiognomie</cell>
                    <cell style="text-align: left;">0.63</cell>
                    <cell style="text-align: left;">0.74</cell>
                    <cell style="text-align: left;">0.68</cell>
                    <cell style="text-align: left;">26</cell>
                </row>
                <row>
                    <cell style="text-align: left;">Rolle</cell>
                    <cell style="text-align: left;">0.06</cell>
                    <cell style="text-align: left;">0.51</cell>
                    <cell style="text-align: left;">0.55</cell>
                    <cell style="text-align: left;">44</cell>
                </row>
            </table>
            <p>Tabelle 2: Klassifikationsergebnisse für das Erkennen von Figureneigenschaften</p>
           </div>
            <div type="div1" rend="DH-Heading1"><head>5. Ausblick</head>
            <p>Geplante Arbeitspakete betreffen vor allem die Automatisierung der vergleichenden Annotation und die Verbesserung der automatischen Erkennung der Kategorien. Eine weitere offene Frage ist der ideale Kotext, den es braucht, um automatisiert Entscheidungen bezüglich der Figureneigenschaften zu treffen.</p>
           </div>
        </body>
            <back>
                <div type="bibliogr">
                    <listBibl>
                        <head>Bibliographie</head>
            <bibl><hi rend="bold">Clark, Kevin, Minh-Thang Luong, Quoc V. Le und Christopher D. Manning</hi>. 2020. “ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators”. In International Conference on Learning Representations (
                <hi rend="italic">ICLR) 2020</hi>. 
                <ref target="https://openreview.net/pdf?id=r1xMH1BtvB">
                    <hi rend="underline color(1155CC)">https://openreview.net/pdf?id=r1xMH1BtvB</hi>
                </ref> (zugegriffen: 27. November 2024).
            </bibl>
            <bibl><hi rend="bold">Devlin, Jacob, Ming-Wei Chang, Kenton Lee und Kristina Toutanova</hi>. 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”. In 
                <hi rend="italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</hi>, 4171–4186. 
                <ref target="https://www.aclweb.org/anthology/N19-1423">
                    <hi rend="underline color(1155CC)">https://www.aclweb.org/anthology/N19-1423</hi>
                </ref> (zugegriffen: 27. November 2024).
            </bibl>
            <bibl><hi rend="bold">Epple, Angelika und Walter Erhart</hi>. 2020. “Practices of Comparing: A New Research Agenda Between Typological and Historical Approaches”. In 
                <hi rend="italic">Practices of Comparing: Towards a new understanding of a fundamental human practice</hi>, hg. von Angelika Epple, Walter Erhart und Johannes Grave, 11–38. Bielefeld: transcript.
            </bibl>
            <bibl><hi rend="bold">Epple, Angelika, Walter Erhart und Johannes Grave</hi>. 2020. 
                <hi rend="italic">Practices of comparing: Towards a new understanding of a fundamental human practice</hi>. Bielefeld: transcript.
            </bibl>
            <bibl><hi rend="bold">Forster, Edward Morgan</hi>. 1949. Ansichten des Romans. Berlin: Suhrkamp.</bibl>
            <bibl><hi rend="bold">Gius, Evelyn, Svenja Guhr und Inna Uglanova</hi>. 2021. ““d-Prose 1870–1920” a Collection of German Prose Texts from 1870 to 1920”, In 
                <hi rend="italic">Journal of Open Humanities Data</hi>
                <hi rend="background(white)" xml:space="preserve">, 7(0), 11. </hi>
                <ref target="https://doi.org/10.5334/johd.30">
                    <hi rend="underline color(1155CC) background(white)">https://doi.org/10.5334/johd.30</hi>
                </ref>
                <hi rend="background(white)">.</hi>
            </bibl>
            <bibl>
                <hi rend="background(white)"><hi rend="bold">Hansen, Per Krogh</hi>. 2000. Die Rolle des Charakters. Aspekte einer literarischen Charakterologie. PhD diss., Aalborg University.</hi>
            </bibl>
            <bibl>
                <hi rend="background(white)" xml:space="preserve"><hi rend="bold">Jannidis, Fotis</hi>. 2004. “Figur und Person. Beitrag zu einer historischen Narratologie”. In </hi>
                <hi rend="italic background(white)">Narratologia. Beiträge zur Erzähltheorie Band 3</hi>
                <hi rend="background(white)">, hg. von Fotis Jannidis, John Pier und Wolf Schmid. Berlin/New York: De Gruyter.</hi>
            </bibl>
            <bibl><hi rend="bold">Liu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer und Veselin Stoyanov</hi>. 2019. 
                <hi rend="italic">RoBERTa: A Robustly Optimized BERT Pretraining Approach.</hi> In 
                <hi rend="italic">arXiv</hi>. 
                <ref target="https://doi.org/10.48550/arXiv.1907.11692">
                    <hi rend="underline color(1155CC)">https://doi.org/10.48550/arXiv.1907.11692</hi>
                </ref>
            </bibl>
            <bibl><hi rend="bold">Müller, Wolfgang G</hi>. 1991. “Interfigurality. A Study on the Interdependence of Literary Figures”. In 
                <hi rend="italic">Intertextuality</hi>, hg. von Heinrich. F. Plett, 101–122. Berlin/New York: De Gruyter.
            </bibl>
            <bibl>
                <hi rend="background(white)" xml:space="preserve"><hi rend="bold">Pagel, Janis, Nils Reiter, Ina Rösiger und Sarah Schulz</hi>. 2020. “Annotation als flexibel einsetzbare Methode.” In </hi>
                <hi rend="italic">Reflektierte algorithmische Textanalyse: Interdisziplinäre(s) Arbeiten in der CRETA-Werkstatt</hi>
                <hi rend="background(white)" xml:space="preserve">, hg. von Janis Pagel, Nils Reiter, Ina Rösiger und Sarah Schulz, 125–142. Berlin, Boston: De Gruyter. </hi>
                <ref target="https://doi.org/10.1515/9783110693973-006">
                    <hi rend="underline color(6789A8)">https://doi.org/10.1515/9783110693973-006</hi>
                </ref>
                <hi rend="background(white)">.</hi>
            </bibl>
            <bibl>
                <hi rend="background(white)" xml:space="preserve"><hi rend="bold">Schlechtweg, Dominik, Barbara McGillivray, Simon Hengchen, Haim Dubossarsky und Nina Tahmasebi</hi>. 2020. </hi>
                <ref target="https://aclanthology.org/2020.semeval-1.1">
                    <hi rend="background(white)">SemEval-2020 Task 1: Unsupervised Lexical Semantic Change Detection</hi>
                </ref>
                <hi rend="background(white)" xml:space="preserve">. In </hi>
                <hi rend="italic background(white)">Proceedings of the Fourteenth Workshop on Semantic Evaluation</hi>
                <hi rend="background(white)">, pages 1–23, Barcelona (online). International Committee for Computational Linguistics.</hi>
            </bibl>
            <bibl><hi rend="bold">Schlechtweg, Dominik und Serge 
                <hi rend="background(white)" xml:space="preserve">Kotchourko (o.D.)</hi>. </hi>
                <hi rend="italic background(white)">PhiTag. Annotationsplattform</hi>
                <hi rend="background(white)" xml:space="preserve">. URL: </hi>
                <ref target="https://phitag.ims.uni-stuttgart.de/">
                    <hi rend="underline color(1155CC) background(white)">https://phitag.ims.uni-stuttgart.de/</hi>
                </ref> (zugegriffen: 27. November 2024).
            </bibl>
            <bibl><hi rend="bold">Unsworth, John</hi>. 2000. 
                <hi rend="italic">Scholarly Primitives: What methods do humanities researchers have in common, and how might our tools reflect this?</hi>
                <ref target="https://johnunsworth.name/Kings.5-00/primitives.html">
                    <hi rend="underline color(1155CC)">https://johnunsworth.name/Kings.5-00/primitives.html</hi>
                </ref> (zugegriffen: 27. November 2024).
            </bibl>
                    </listBibl>
                </div>
            </back>
    </text>
</TEI>
