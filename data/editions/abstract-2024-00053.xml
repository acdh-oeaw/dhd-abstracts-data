<?xml version="1.0" encoding="utf-8"?>
<TEI xml:id="KLAUK_Stephanie_KI_und_Musik_in_der_Lehre___Ein_musikwissens" xmlns="http://www.tei-c.org/ns/1.0">
<teiHeader>
<fileDesc>
<titleStmt>
<title>KI und Musik in der Lehre - Ein musikwissenschaftliches Projekt der Universität des Saarlandes (UdS)</title>
<author>
<persName>
<surname>Schmolenzky</surname>
<forename>Pascal</forename>
</persName>
<affiliation>Universität des Saarlandes, Deutschland</affiliation>
<email>s8plschm@stud.uni-saarland.de</email>
</author>
<author>
<persName>
<surname>Klauk</surname>
<forename>Stephanie</forename>
</persName>
<affiliation>Universität des Saarlandes, Deutschland</affiliation>
<email>s.klauk@mx.uni-saarland.de</email>
</author>
</titleStmt>
<editionStmt>
<edition>
<date>2023-12-06T16:07:00Z</date>
</edition>
</editionStmt>
<publicationStmt>
<publisher>Digital Humanities Passau</publisher>
<address>
<addrLine>Universität Passau</addrLine>
<addrLine>Innstraße 41</addrLine>
<addrLine>D-94032 Passau</addrLine>
<addrLine>Deutschland</addrLine>
</address>
<idno subtype="zenodo" type="url">https://zenodo.org/records/10698410</idno></publicationStmt>
<sourceDesc>
<p>Converted from a Word document</p>
</sourceDesc>
</fileDesc>
<encodingDesc>
<appInfo>
<application ident="DHCONVALIDATOR" version="1.22">
<label>DHConvalidator</label>
</application>
</appInfo>
</encodingDesc>
<profileDesc>
<textClass>
<keywords n="category" scheme="ConfTool">
<term>Paper</term>
</keywords>
<keywords n="subcategory" scheme="ConfTool">
<term>Posterpräsentation</term>
</keywords>
<keywords n="keywords" scheme="ConfTool">
<term>KI</term>
<term>Geisteswissenschaften</term>
<term>Lehre</term>
<term>Musik</term>
<term>Musikwissenschaft</term>
</keywords>
<keywords n="topics" scheme="ConfTool">
<term>Lehre</term>
<term>Projekte</term>
<term>Ton</term>
<term>Text</term>
<term>Werkzeuge</term>
</keywords>
</textClass>
</profileDesc>
</teiHeader>
<text>
<body>
<div rend="DH-Heading1" type="div1">
<head>Einleitung</head>
<p style="text-align: left; ">Mit der Veröffentlichung von 
                    <hi rend="italic">ChatGPT</hi><ref n="1" target="ftn1"/> durch das US-amerikanische Unternehmen 
                    <hi rend="italic">OpenAi</hi> im vergangenen Jahr erhielt der durch die Coronakrise ausgelöste Digitalisierungsschub in der Hochschullehre einen neuen Impuls. Als Reaktion darauf wurde an der Universität des Saarlandes die Initiative „KI in der Lehre“ ins Leben gerufen, die Teil des seit 2021 von der Stiftung Innovation in der Hochschullehre geförderten Projekts 
                    <hi rend="italic">Digital Teaching Plug-in</hi> (<hi rend="italic">DaTa-Pin</hi>) bildet. Herausforderungen und Möglichkeiten der Nutzung von KI sollen in innovativen Lehr- und Lernangeboten erprobt und ausgelotet, im Idealfall in Best-Practice-Ansätze überführt werden. 
                </p>
<p style="text-align: left; ">Die Besonderheit des von der Fachrichtung Musikwissenschaft betreuten Teilprojekts „KI und Musik“ bildet sein multimodaler Ansatz. Im Gegensatz zu vielen anderen geisteswissenschaftlichen Fächern sind dort KI-Anwendungen nicht auf Schrift oder Texte beschränkt, sondern beziehen Ton und Musik mit ein. In diesem Beitrag werden das auf zwei Semester angelegte Teilprojekt und erste Ergebnisse vorgestellt.</p>
</div>
<div rend="DH-Heading1" type="div1">
<head>Projektvorstellung</head>
<p style="text-align: left; ">Die Umsetzung des Teilprojekts „KI und Musik“ im Lehrangebot der Studiengänge Musikwissenschaft und Musikmanagement der UdS bezieht sich auf die Komponenten Textproduktion und Musikproduktion. Beide subsumieren jeweils spezifische Anwendungsszenarien und digitale Werkzeuge. Für den Bereich Textproduktion spielt die Verwendung des Sprachmodells 
                    <hi rend="italic">ChatGPT</hi>, das Studierende unter Einhaltung verbindlicher Regeln einsetzen sollen (Spannagel, 2023), eine wesentliche Rolle. In unterschiedlichen Lehrveranstaltungen, in denen die Generierung verschiedener Textarten im Mittelpunkt steht ‒<!--‒--> wissenschaftliche Hausarbeiten in Seminaren zur Musikgeschichte, Rezensionen und Musikkritiken in Übungen zum musikjournalistischen Schreiben sowie Liedtexte in Praxisveranstaltungen wie Songwriting ‒<!--‒-->, sollen dafür How-to-Konzepte entwickelt werden, die teilweise auch auf die Lehre anderer geisteswissenschaftlicher Fächer übertragbar sind. 
                </p>
<p style="text-align: left; ">Im fachspezifischen Anwendungsbereich werden computergestützte Verfahren und KI-Tools seit Jahrzehnten zur Komposition, Produktion, Aufführung und Analyse von Musik genutzt und in Forschungsprojekten stetig weiterentwickelt. Ein systematischer Einsatz solcher generativen Modelle auf Basis symbolischer Daten oder Audiodaten in der musikwissenschaftlichen Hochschullehre lässt sich allerdings nicht beobachten (vgl. zur Verwendung im Instrumentalspiel Yu et al. 2023). Hier setzt das Projekt mit der Einbindung musikbezogener KI-Werkzeuge in Lehrveranstaltungen zur Analyse und Komposition (<hi rend="italic">EarMaster</hi>) und Bearbeitung von Musik (<hi rend="italic">Timbre Transfer</hi>; vgl. Gabrielli et al. 2018) an.  
                </p>
</div>
<div rend="DH-Heading1" type="div1">
<head>Erste Projektphase: Sommersemester 2023</head>
<p style="text-align: left; ">Aus dem Bereich Musikproduktion wurde zunächst die KI-basierte App 
                    <hi rend="italic">EarMaster</hi> in die musiktheoretische Übung Gehörbildung implementiert. Das Trainingsprogramm zum Üben und Erkennen von Intervallen und Akkorden wird individuell auf die Fähigkeiten und Defizite der Lernenden angepasst und erlaubt gleichzeitig eine stetige Dokumentation des Lernfortschritts (Martínez Villar, 2015). Die Präsenzveranstaltung wurde damit um eine asynchrone Selbstlernphase (Flipped-Classroom, vgl. Bergmann et al. 2012) erweitert, die deutlich stärker genutzt wurde als zusätzliche synchrone Lernangebote wie Tutorien. Eine Lernoptimierung durch die App lässt sich an den Prüfungsergebnissen des Sommersemesters ablesen, die im Vergleich zu Zwischenprüfungen noch ohne die digitale Übemöglichkeit signifikant besser ausgefallen sind. 
                </p>
<p style="text-align: left; ">Für die ersten Schritte im Bereich Textproduktion wurde eine musikjournalistische Übung ausgewählt, in der eine Filmmusik-Rezension verfasst werden sollte. Die Verwendung von 
                    <hi rend="italic">ChatGPT</hi> hat gezeigt, wie wichtig ein qualifizierter Umgang damit ist, für den für die zweite Projektphase erste How-to-Konzepte erarbeitet wurden. Hierzu zählt das Formulieren effektiver Anfragen (vgl. Gimpel et al. 2023), die kritische Beschäftigung mit den Ergebnissen der KI sowie die Kenntnis ihrer Funktionsweise. Außerdem wurden mögliche Grenzen der Automatisierung geistiger Arbeit aufgezeigt, da das kreative Schreiben über das kreative Medium Musik offenbar besondere Herausforderungen für das KI-Tool darstellt.  
                </p>
</div>
<div rend="DH-Heading1" type="div1">
<head>Zweite Projektphase: Wintersemester 2023/24</head>
<p style="text-align: left; ">In der Kernphase des Projekts werden belastbare Evaluationen durchgeführt und die Erfahrungen aus der ersten Projektphase konzeptionell eingebracht.</p>
<p style="text-align: left; ">Neben flankierenden Kursen wie „Songwriting“ und „Methoden der Analyse“ werden im Seminar „Komponieren im digitalen Zeitalter: AI und Human-Computer Co-Creativity“ KI-basierte Text- und Musikproduktion zusammengeführt. In dem als Flipped-Classroom ausgerichteten Seminar sollen die Studierenden eine wissenschaftliche Hausarbeit zum Thema Musikproduktion mithilfe von 
                    <hi rend="italic">ChatGPT</hi> und verschiedenen Recherche-Tools (<hi rend="italic">Connected Papers</hi><ref n="2" target="ftn2"/>, 
                    <hi rend="italic">Elicit</hi><ref n="3" target="ftn3"/>, 
                    <hi rend="italic">Perplexity</hi><ref n="4" target="ftn4"/> u. a.) prozessbegleitend schreiben. Nach der Themenvergabe zu Beginn des Semesters kommen erarbeitete How-to-Konzepte und Prompting-Strategien zur Anwendung. Die inhaltliche Ausrichtung auf KI-gestützte Kompositionen schließt insbesondere auch die Möglichkeit zu eigenen Komposititionsprojekten der Studierenden ein. Dabei kommen Tools wie z. B. 
                    <hi rend="italic">Wekinator</hi><ref n="5" target="ftn5"/>, 
                    <hi rend="italic">Jukebox</hi><ref n="6" target="ftn6"/> oder 
                    <hi rend="italic">ChatGPT</hi> zur Generierung von MIDI-Daten zum Einsatz.
                </p>
<p style="text-align: left; ">Asynchrone Lernphasen werden genutzt, um Texte zu wissenschaftlichen Fragestellungen zu generieren. In synchronen Classroom-Phasen dienen die generierten Texte als Ausgangspunkt einer vorwiegend methodischen Diskussion zwischen Studierenden und Dozierenden (vgl. Weinmann-Sandig, 2023), bei denen ein transparenter Umgang mit Ergebnissen und „Prompts“ gepflegt wird. Die Dokumentation und Evaluation der zweiten Projektphase soll im Poster präsentiert werden.</p>
</div>
</body>
<back>
<div type="notes">
<note n="1" rend="footnote text" xml:id="ftn1">
<ref target="https://openai.com/blog/chatgpt">https://openai.com/blog/chatgpt</ref>
</note>
<note n="2" rend="footnote text" xml:id="ftn2">
<ref target="https://www.connectedpapers.com/">https://www.connectedpapers.com/</ref>
</note>
<note n="3" rend="footnote text" xml:id="ftn3">
<ref target="https://elicit.com/">https://elicit.com/</ref>
</note>
<note n="4" rend="footnote text" xml:id="ftn4">
<ref target="https://www.perplexity.ai/">https://www.perplexity.ai/</ref>
</note>
<note n="5" rend="footnote text" xml:id="ftn5">
<ref target="http://www.wekinator.org/">http://www.wekinator.org/</ref>
</note>
<note n="6" rend="footnote text" xml:id="ftn6">
<ref target="https://openai.com/research/jukebox">https://openai.com/research/jukebox</ref>
</note></div>
<div type="bibliogr">
<listBibl>
<head>Bibliographie</head>
<bibl style="text-align: left; ">
<hi rend="bold">Bergmann, Jonathan und Aaron Sams.</hi> 2012. 
                        <hi rend="italic">Flip your classroom. Reach every student in every class every day</hi>. Eugene, OR: International Society for Technology in Education.
                    </bibl>
<bibl style="text-align: left; ">
<hi rend="bold">Gabrielli, Leonardo, Carmine-Emanuele Cella, Fabio Vesperini, Diego Droghini, Emanuele Principi und Stefano Squartini.</hi> 2018. “Deep Learning for Timbre Modification and Transfer: an Evaluation Study.” In 
                        <hi rend="italic">Proceeding of the 144th Audio Engineering Society Convention</hi>. https://www.researchgate.net/publication/330842404_Deep_Learning_for_Timbre_Modification<p/>_and_Transfer_an_Evaluation_Study (zugegriffen: 19. Juli 2023).
                    </bibl>
<bibl style="text-align: left; ">
<hi rend="bold">Gimpel, Henner, Kristina Hall, Stefan Decker, Torsten Eymann, Luis Lämmermann, Alexander Mädche, Maximilian Röglinger, et al.</hi> 2023. 
                        <hi rend="italic">Unlocking the Power of Generative AI Models and Systems such as GPT-4 and ChatGPT for Higher Education</hi>. https://digital.uni-hohenheim.de/fileadmin/einrichtungen/digital/Generative_AI_and_ChatGPT_in_Higher_Education.pdf (zugegriffen: 17. Juli 2023).
                    </bibl>
<bibl style="text-align: left; ">
<hi rend="bold">Martínez Villar, Sofía.</hi> 2015. “Online Ear Training Programmes and Systems: Advantages and Disadvantages.” In 
                        <hi rend="italic">3. CEIMUS Congress</hi>. https://sonograma.org/2015/06/ear-training-programmes-systems/ (zugegriffen 19. Juli 2023).
                    </bibl>
<bibl style="text-align: left; ">
<hi rend="bold">Spannagel, Christian.</hi> 2023. 
                        <hi rend="italic">Rules for Tools</hi>. https://csp.uber.space/phhd/rulesfortools.pdf (zugegriffen: 17. Juli 2023).
                    </bibl>
<bibl style="text-align: left; ">
<hi rend="bold">Weinmann-Sandig, Nina.</hi> 2023. 
                        <hi rend="italic">ChatGPT – Eine Chance zur Wiederbelebung des kritischen Denkens in der Hochschullehre</hi>. https: //hochschulforumdigitalisierung.de/de/blog/praxistest-chatgpt-weimann-sandig (zugegriffen: 17. Juli 2023).
                    </bibl>
<bibl style="text-align: left; ">
<hi rend="bold">Yu, Xiaofei, Ning Ma, Lei Zheng, Licheng Wang und Kai Wang.</hi> 2023. “Developments and Applications of Artificial Intelligence in Music Education.” In 
                        <hi rend="italic">Technologies</hi> 11. https://www.mdpi.com/2227-7080/11/2/42 (zugegriffen: 18. Juli 2023).
                    </bibl>
</listBibl>
</div>
</back>
</text>
</TEI>